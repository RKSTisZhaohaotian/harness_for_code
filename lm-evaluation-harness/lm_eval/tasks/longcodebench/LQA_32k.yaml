task: LQA_32k
dataset_name: LQA_32k
dataset_path: json
test_split: test
dataset_kwargs:
   data_files: 
      test: /Users/zhaohaotian/Desktop/harness/lm-evaluation-harness/lm_eval/local_data/longcodebench/LQA/32K.jsonl
output_type: generate_until
doc_to_text: "{{prompt.strip()}}\nGive your answer in the format of 'the answer is X' where X is the correct letter choice."
doc_to_target: correct_letter
filter_list:
  - name: "custom-extract"
    filter:
      - function: "regex"
        regex_pattern: 'answer is \(?([ABCDEFGHIJ])\)?'
        # regex_pattern: r".*[aA]nswer:\s*([A-J])",
      - function: "take_first"
generation_kwargs:
  until: '<|endoftext|>'
  max_gen_toks: 4096
  do_sample: false
  temperature: 0.0
metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true
    ignore_case: true
    ignore_punctuation: true
metadata:
  local_data: true